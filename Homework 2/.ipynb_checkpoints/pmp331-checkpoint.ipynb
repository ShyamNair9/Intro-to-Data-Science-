{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Data Science\n",
    "## Homework 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student Name: Parth Patel \n",
    "\n",
    "Student Netid: pmp331\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Case study\n",
    "- Read [this article](http://www.nytimes.com/2012/02/19/magazine/shopping-habits.html) in the New York Times.\n",
    "- Use what we've learned in class and from the book to describe how one could set Target's problem up as a predictive modeling problem, such that they could have gotten the results that they did.  Formulate your solution as a proposed plan using our data science terminology.  Include all the aspects of the formulation that you see as relevant to solving the problem.  Be precise but concise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target like almost every major retailer, from grocery chains to investment banks to the USPS, has a “predictive analytics” department devoted to understanding not just the consumers’ shopping list but also their personal habits, so as to more efficiently market to them.\n",
    "\n",
    "Target wanted an answer to a simple question, “Is their customer pregnant, even if she doesn’t want them to know?”, since, new parents are retailer’s holy grail as mentioned in the article. If they could identify pregnant shoppers, they could earn millions, which they eventually did. So earning money by targeting the to-be parents to buy baby products along with other primary households later was the business motivation behind this analysis. Target wanted to target this portion of the population before any of its competitors got hold of them.\n",
    "\n",
    "The first step that is needed to be taken before one could find a solution to these types of questions is creating a dataset, in which one could find patterns in. From the article, it’s clear that birth records are public, and can be easily availed by the companies. This could act as one of the data sources. The other sources could be surveys conducted by Target for female customers. The main and the most valuable spruce would be customer data that they gather, containing information like, if customer uses a credit card or a coupon, or mail in a refund, or call the customer help line, or open an e-mail they sent to customer or visit their Web site. After cleaning and merging data from all these sources, they could have sliced just the data needed for predicting whether customer is pregnant or not. Like the data of just the female customers, containing features like the products bought by them, age, marital status are some of them. Training set could be female customers who have babies and finding which products did they buy during their pregnancy as the DOB of their baby would be easily available through the public records.\n",
    "\n",
    "The target variable is whether the customer is pregnant or not. I would recommend the SVM (Support Vector Model) model here because given a set of training data, each marked for belonging to one of two categories (pregnant – Yes/No), a SVM training algorithm builds a model that assigns new examples into one category or the other, making it a non-probabilistic binary linear classifier.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grader  : 5.0/ 5.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Exploring data in the command line\n",
    "For this part we will be using the data file located in `\"data/advertising_events.csv\"`. This file consists of records that pertain to some online advertising events on a given day. There are 4 comma separated columns in this order: `userid`, `timestamp`, `domain`, and `action`. These fields are of type `int`, `int`, `string`, and `int` respectively. Answer the following questions using Linux/Unix bash commands. All questions can be answered in one line (sometimes, with pipes)! Some questions will have many possible solutions. Don't forget that in IPython notebooks you must prefix all bash commands with an exclamation point, i.e. `\"!command arguments\"`.\n",
    "\n",
    "[Hints: You can experiment with whatever you want in the notebook and then delete things to construct your answer later.  You can also use ssh to use the actual bash shell on EC2 (see original directions) and then just paste your answers here. Recall that once you enter the \"!\" then filename completion should work.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. How many records (lines) are in this file?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10341 advertising_events.csv\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l advertising_events.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. How many unique users are in this file? (hint: consider the 'cut' command and use pipe operator '|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "732\r\n"
     ]
    }
   ],
   "source": [
    "!cut -d, -f1 advertising_events.csv | sort | uniq | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Rank all domains by the number of visits they received in descending order. (hint: consider the 'cut', 'uniq' and 'sort' commands and the pipe operator)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    513 wikipedia.org\r\n",
      "    511 amazon.com\r\n",
      "    382 qq.com\r\n",
      "    321 twitter.com\r\n",
      "    316 taobao.com\r\n",
      "   3114 google.com\r\n",
      "   2092 facebook.com\r\n",
      "   1036 youtube.com\r\n",
      "   1034 yahoo.com\r\n",
      "   1022 baidu.com\r\n"
     ]
    }
   ],
   "source": [
    "cut -d, -f3 advertising_events | sort | uniq -c | sort -r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. List all records for the user with user id 37. (hint: this can be done using 'grep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37,648061658,google.com,0\r\n",
      "37,642479972,google.com,2\r\n",
      "37,644493341,facebook.com,2\r\n",
      "37,654941318,facebook.com,1\r\n",
      "37,649979874,baidu.com,1\r\n",
      "37,653061949,yahoo.com,1\r\n",
      "37,655020469,google.com,3\r\n",
      "37,640878012,amazon.com,0\r\n",
      "37,659864136,youtube.com,1\r\n",
      "37,640361378,yahoo.com,1\r\n",
      "37,653862134,facebook.com,0\r\n",
      "37,648828970,youtube.com,0\r\n"
     ]
    }
   ],
   "source": [
    "!grep '^37,' advertising_events.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Dealing with data Pythonically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# You might find these packages useful. You may import any others you want!\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. Load the data set `\"data/ads_dataset.tsv\"` into a Python Pandas data frame called `ads`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ads = pd.read_csv(r\"C:\\Users\\parth\\OneDrive\\Documents\\Jupyter Lab\\ads_dataset.tsv\", sep = \"\\t\")\n",
    "ads = pd.read_csv(\"data/ads_dataset.tsv\", sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Write a Python function called `getDfSummary()` that does the following:\n",
    "- Takes as input a data frame\n",
    "- For each variable in the data frame calculates the following features:\n",
    "  - `number_nan` to count the number of missing not-a-number values\n",
    "  - Ignoring missing, NA, and Null values:\n",
    "    - `number_distinct` to count the number of distinct values a variable can take on\n",
    "    - `mean`, `max`, `min`, `std` (standard deviation), and `25%`, `50%`, `75%` to correspond to the appropriate percentiles\n",
    "- All of these new features should be loaded in a new data frame. Each row of the data frame should be a variable from the input data frame, and the columns should be the new summary features.\n",
    "- Returns this new data frame containing all of the summary information\n",
    "\n",
    "Hint: The pandas `describe()` [(manual page)](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.describe.html) method returns a useful series of values that can be used here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variable</th>\n",
       "      <th>number_nan</th>\n",
       "      <th>number_distinct</th>\n",
       "      <th>mean</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>std</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0 </th>\n",
       "      <td>             isbuyer</td>\n",
       "      <td>     0</td>\n",
       "      <td>     2</td>\n",
       "      <td>   0.042632</td>\n",
       "      <td>     1.00000</td>\n",
       "      <td>   0.0000</td>\n",
       "      <td>    0.202027</td>\n",
       "      <td>   0</td>\n",
       "      <td>   0</td>\n",
       "      <td>   0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1 </th>\n",
       "      <td>            buy_freq</td>\n",
       "      <td> 52257</td>\n",
       "      <td>    11</td>\n",
       "      <td>   1.240653</td>\n",
       "      <td>    15.00000</td>\n",
       "      <td>   1.0000</td>\n",
       "      <td>    0.782228</td>\n",
       "      <td>   1</td>\n",
       "      <td>   1</td>\n",
       "      <td>   1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2 </th>\n",
       "      <td>          visit_freq</td>\n",
       "      <td>     0</td>\n",
       "      <td>    64</td>\n",
       "      <td>   1.852777</td>\n",
       "      <td>    84.00000</td>\n",
       "      <td>   0.0000</td>\n",
       "      <td>    2.921820</td>\n",
       "      <td>   1</td>\n",
       "      <td>   1</td>\n",
       "      <td>   2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3 </th>\n",
       "      <td>        buy_interval</td>\n",
       "      <td>     0</td>\n",
       "      <td>   295</td>\n",
       "      <td>   0.210008</td>\n",
       "      <td>   174.62500</td>\n",
       "      <td>   0.0000</td>\n",
       "      <td>    3.922016</td>\n",
       "      <td>   0</td>\n",
       "      <td>   0</td>\n",
       "      <td>   0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4 </th>\n",
       "      <td>         sv_interval</td>\n",
       "      <td>     0</td>\n",
       "      <td>  5886</td>\n",
       "      <td>   5.825610</td>\n",
       "      <td>   184.91670</td>\n",
       "      <td>   0.0000</td>\n",
       "      <td>   17.595442</td>\n",
       "      <td>   0</td>\n",
       "      <td>   0</td>\n",
       "      <td>   0.104167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5 </th>\n",
       "      <td>   expected_time_buy</td>\n",
       "      <td>     0</td>\n",
       "      <td>   348</td>\n",
       "      <td>  -0.198040</td>\n",
       "      <td>    84.28571</td>\n",
       "      <td>-181.9238</td>\n",
       "      <td>    4.997792</td>\n",
       "      <td>   0</td>\n",
       "      <td>   0</td>\n",
       "      <td>   0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6 </th>\n",
       "      <td> expected_time_visit</td>\n",
       "      <td>     0</td>\n",
       "      <td> 15135</td>\n",
       "      <td> -10.210786</td>\n",
       "      <td>    91.40192</td>\n",
       "      <td>-187.6156</td>\n",
       "      <td>   31.879722</td>\n",
       "      <td>   0</td>\n",
       "      <td>   0</td>\n",
       "      <td>   0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7 </th>\n",
       "      <td>            last_buy</td>\n",
       "      <td>     0</td>\n",
       "      <td>   189</td>\n",
       "      <td>  64.729335</td>\n",
       "      <td>   188.00000</td>\n",
       "      <td>   0.0000</td>\n",
       "      <td>   53.476658</td>\n",
       "      <td>  18</td>\n",
       "      <td>  51</td>\n",
       "      <td> 105.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8 </th>\n",
       "      <td>          last_visit</td>\n",
       "      <td>     0</td>\n",
       "      <td>   189</td>\n",
       "      <td>  64.729335</td>\n",
       "      <td>   188.00000</td>\n",
       "      <td>   0.0000</td>\n",
       "      <td>   53.476658</td>\n",
       "      <td>  18</td>\n",
       "      <td>  51</td>\n",
       "      <td> 105.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9 </th>\n",
       "      <td>        multiple_buy</td>\n",
       "      <td>     0</td>\n",
       "      <td>     2</td>\n",
       "      <td>   0.006357</td>\n",
       "      <td>     1.00000</td>\n",
       "      <td>   0.0000</td>\n",
       "      <td>    0.079479</td>\n",
       "      <td>   0</td>\n",
       "      <td>   0</td>\n",
       "      <td>   0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>      multiple_visit</td>\n",
       "      <td>     0</td>\n",
       "      <td>     2</td>\n",
       "      <td>   0.277444</td>\n",
       "      <td>     1.00000</td>\n",
       "      <td>   0.0000</td>\n",
       "      <td>    0.447742</td>\n",
       "      <td>   0</td>\n",
       "      <td>   0</td>\n",
       "      <td>   1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>           uniq_urls</td>\n",
       "      <td>     0</td>\n",
       "      <td>   207</td>\n",
       "      <td>  86.569343</td>\n",
       "      <td>   206.00000</td>\n",
       "      <td>  -1.0000</td>\n",
       "      <td>   61.969765</td>\n",
       "      <td>  30</td>\n",
       "      <td>  75</td>\n",
       "      <td> 155.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>        num_checkins</td>\n",
       "      <td>     0</td>\n",
       "      <td>  4628</td>\n",
       "      <td> 720.657592</td>\n",
       "      <td> 37091.00000</td>\n",
       "      <td>   1.0000</td>\n",
       "      <td> 1275.727306</td>\n",
       "      <td> 127</td>\n",
       "      <td> 319</td>\n",
       "      <td> 802.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>               y_buy</td>\n",
       "      <td>     0</td>\n",
       "      <td>     2</td>\n",
       "      <td>   0.004635</td>\n",
       "      <td>     1.00000</td>\n",
       "      <td>   0.0000</td>\n",
       "      <td>    0.067924</td>\n",
       "      <td>   0</td>\n",
       "      <td>   0</td>\n",
       "      <td>   0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               variable  number_nan  number_distinct        mean          max  \\\n",
       "0               isbuyer           0                2    0.042632      1.00000   \n",
       "1              buy_freq       52257               11    1.240653     15.00000   \n",
       "2            visit_freq           0               64    1.852777     84.00000   \n",
       "3          buy_interval           0              295    0.210008    174.62500   \n",
       "4           sv_interval           0             5886    5.825610    184.91670   \n",
       "5     expected_time_buy           0              348   -0.198040     84.28571   \n",
       "6   expected_time_visit           0            15135  -10.210786     91.40192   \n",
       "7              last_buy           0              189   64.729335    188.00000   \n",
       "8            last_visit           0              189   64.729335    188.00000   \n",
       "9          multiple_buy           0                2    0.006357      1.00000   \n",
       "10       multiple_visit           0                2    0.277444      1.00000   \n",
       "11            uniq_urls           0              207   86.569343    206.00000   \n",
       "12         num_checkins           0             4628  720.657592  37091.00000   \n",
       "13                y_buy           0                2    0.004635      1.00000   \n",
       "\n",
       "         min          std  25%  50%         75%  \n",
       "0     0.0000     0.202027    0    0    0.000000  \n",
       "1     1.0000     0.782228    1    1    1.000000  \n",
       "2     0.0000     2.921820    1    1    2.000000  \n",
       "3     0.0000     3.922016    0    0    0.000000  \n",
       "4     0.0000    17.595442    0    0    0.104167  \n",
       "5  -181.9238     4.997792    0    0    0.000000  \n",
       "6  -187.6156    31.879722    0    0    0.000000  \n",
       "7     0.0000    53.476658   18   51  105.000000  \n",
       "8     0.0000    53.476658   18   51  105.000000  \n",
       "9     0.0000     0.079479    0    0    0.000000  \n",
       "10    0.0000     0.447742    0    0    1.000000  \n",
       "11   -1.0000    61.969765   30   75  155.000000  \n",
       "12    1.0000  1275.727306  127  319  802.000000  \n",
       "13    0.0000     0.067924    0    0    0.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getDfSummary(input_data):\n",
    "    #Initialize the lists which will store the computed data\n",
    "    attr_name = []\n",
    "    number_nan = []\n",
    "    number_distinct = []\n",
    "    mean = []\n",
    "    max_number = []\n",
    "    min_number = []\n",
    "    std = []\n",
    "    q25 = []\n",
    "    q50 = []\n",
    "    q75 = []\n",
    "    \n",
    "    #Code to loop through the columns of data frame and calculate needed data\n",
    "    for column in input_data.columns:\n",
    "        attr_name.append(column)\n",
    "        number_nan.append(ads[column].isnull().sum())\n",
    "        number_distinct.append(len(ads[column].unique()))\n",
    "        mean.append(ads[column].mean())\n",
    "        max_number.append(ads[column].max())\n",
    "        min_number.append(ads[column].min())\n",
    "        std.append(ads[column].std())\n",
    "        q25.append(ads[column].quantile(0.25))\n",
    "        q50.append(ads[column].quantile(0.5))\n",
    "        q75.append(ads[column].quantile(0.75))\n",
    "    \n",
    "    #Create output data frame and reaarange the columns of data frame according to the order asked in question\n",
    "    output_data = pd.DataFrame({\"variable\":attr_name,\"number_nan\":number_nan, \"number_distinct\":number_distinct, \"mean\":mean, \"max\":max_number, \"min\":min_number, \"std\":std, \"25%\":q25, \"50%\":q50, \"75%\":q75})\n",
    "    output_data = output_data[['variable', 'number_nan', 'number_distinct', 'mean', 'max', 'min', 'std', '25%', '50%', '75%']]\n",
    "        \n",
    "    return output_data\n",
    "\n",
    "#Call the method\n",
    "getDfSummary(ads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. How long does it take for your `getDfSummary()` function to work on your `ads` data frame? Show us the results below.\n",
    "\n",
    "Hint: `%timeit getDfSummary(ads)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 144 ms per loop\n"
     ]
    }
   ],
   "source": [
    "timeit getDfSummary(ads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Using the results returned from `getDfSummary()`, which fields, if any, contain missing `NaN` values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The field(s) with missing NaN values : ', ['buy_freq'])\n"
     ]
    }
   ],
   "source": [
    "odf = getDfSummary(ads)\n",
    "\n",
    "nan_fields = []\n",
    "nan_values = odf['number_nan'].tolist()\n",
    "var_values = odf['variable'].tolist()\n",
    "index = 0\n",
    "\n",
    "for nan_value in nan_values:\n",
    "    if nan_value > 0:\n",
    "        #nan_fields.append(var_values[nan_values.index(nan_value)])\n",
    "        nan_fields.append(var_values[index])\n",
    "    index = index + 1\n",
    "    \n",
    "print('The field(s) with missing NaN values : ', nan_fields)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. For the fields with missing values, does it look like the data is missing at random? Are there any other fields that correlate perfectly, or predict that the data is missing? If missing, what should the data value be?\n",
    "\n",
    "Hint: create another data frame that has just the records with a missing value. Get a summary of this data frame using `getDfSummary()` and compare the differences. Do some feature distributions change dramatically?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ads_nan is another data frame that has just the records with a missing nan value\n",
    "ads_nan = ads[ads.isnull().any(axis = 1)]\n",
    "ads_nan_summary = getDfSummary(ads_nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the summary of the data frame that has just the recordes with missing value, I think they are the records of those customers who haven't bought anything once, they are the people who fall under the category of window shoppers. According to me the correct value of the missing ones should be 0. There's a correlation between the features isbuyer and buy_freq."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\\. Which variables are binary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['isbuyer', 'multiple_buy', 'multiple_visit', 'y_buy']\n"
     ]
    }
   ],
   "source": [
    "odf = getDfSummary(ads)\n",
    "\n",
    "binary_features = []\n",
    "index = 0\n",
    "distinct_values = odf['number_distinct'].tolist()\n",
    "var_values = odf['variable'].tolist()\n",
    "\n",
    "for val in distinct_values:\n",
    "    if val == 2:\n",
    "        binary_features.append(var_values[index])\n",
    "    index = index + 1\n",
    "print(binary_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 : 15/16\n",
    "# Total : 5+3.5 +15 = 23.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
